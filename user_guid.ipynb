{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An user guid of `keras-unet-collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.3.0; Keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: importing `models` from `keras_unet_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: defining your hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1**: A binary classification U-net with:\n",
    "\n",
    "1. Four down- and upsampliung levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. One convolutional layer (after concatenation) per upsamling level.\n",
    "\n",
    "2. ReLU activcation, batch normalization.\n",
    "\n",
    "3. Downsampling through Maxpooling.\n",
    "\n",
    "4. Upsampling through reflective padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = models.unet_2d((64, 64, 3), [64, 128, 256, 512, 1024], n_labels=2,\n",
    "                      stack_num_down=2, stack_num_up=1,\n",
    "                      activation='ReLU', output_activation='Softmax', \n",
    "                      batch_norm=True, pool=True, unpool=True, name='unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**: An attention-Unet for single target regression with:\n",
    "\n",
    "1. three down- and upsampliung levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. Two convolutional layers (after concatenation) per upsamling level.\n",
    "\n",
    "2. ReLU activcation, batch normalization.\n",
    "\n",
    "3. Additive attention, ReLU attention activation\n",
    "        \n",
    "4. downsampling through stride convolutional layers.\n",
    "\n",
    "5. Upsampling through transpose covolutional layers.   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_unet = models.att_unet_2d((64, 64, 3), [64, 128, 256, 512], n_labels=1,\n",
    "                              stack_num_down=2, stack_num_up=2,\n",
    "                              activation='ReLU', atten_activation='ReLU', attention='add', output_activation=None, \n",
    "                              batch_norm=True, pool=False, unpool=False, name='att-unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3**: An U-net++ for three-label classification with:\n",
    "\n",
    "1. three down- and upsampliung levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. Two convolutional layers (after concatenation) per upsamling level.\n",
    "\n",
    "2. LeakyReLU activcation, no batch normalization.\n",
    "        \n",
    "3. Downsampling through Maxpooling.\n",
    "\n",
    "4. Upsampling through transpose covolutional layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnet = models.unet_plus_2d((64, 64, 3), [64, 128, 256, 512], n_labels=3,\n",
    "                           stack_num_down=2, stack_num_up=2,\n",
    "                           activation='LeakyReLU', output_activation='Softmax', \n",
    "                           batch_norm=False, pool=True, unpool=False, name='xnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4**: Going deeper --- adding stacked residual blocks into the Example 3 U-net++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_xnet = models.res_unet_plus_2d((64, 64, 3), [64, 128, 256, 512], n_labels=3,\n",
    "                                   stack_num=2, res_num=2,\n",
    "                                   activation='LeakyReLU', output_activation='Softmax', \n",
    "                                   batch_norm=False, pool=True, unpool=False, name='res_xnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
