{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A user guid of `keras-unet-collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.3.0; Keras 2.4.0\n"
     ]
    }
   ],
   "source": [
    "print('TensorFlow {}; Keras {}'.format(tf.__version__, keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: importing `models` from `keras_unet_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: defining your hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 1**: A binary classification U-net with:\n",
    "\n",
    "1. Four down- and upsampliung levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. One convolutional layer (after concatenation) per upsamling level.\n",
    "\n",
    "2. Gaussian Error Linear Unit (GELU) activcation, batch normalization.\n",
    "\n",
    "3. Downsampling through Maxpooling.\n",
    "\n",
    "4. Upsampling through reflective padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = models.unet_2d((64, 64, 3), [64, 128, 256, 512, 1024], n_labels=2,\n",
    "                      stack_num_down=2, stack_num_up=1,\n",
    "                      activation='GELU', output_activation='Softmax', \n",
    "                      batch_norm=True, pool=True, unpool=True, name='unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**: An attention-Unet for single target regression with:\n",
    "\n",
    "1. three down- and upsampling levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. Two convolutional layers (after concatenation) per upsampling level.\n",
    "\n",
    "2. ReLU activation, batch normalization.\n",
    "\n",
    "3. Additive attention, ReLU attention activation.\n",
    "        \n",
    "4. downsampling through stride convolutional layers.\n",
    "\n",
    "5. Upsampling through transpose convolutional layers.   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_unet = models.att_unet_2d((64, 64, 3), [64, 128, 256, 512], n_labels=1,\n",
    "                              stack_num_down=2, stack_num_up=2,\n",
    "                              activation='ReLU', atten_activation='ReLU', attention='add', output_activation=None, \n",
    "                              batch_norm=True, pool=False, unpool=False, name='att-unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3**: a modified U-net++ for three-label classification with:\n",
    "\n",
    "1. three down- and upsampling levels.\n",
    "\n",
    "2. Two convolutional layers per downsampling level.\n",
    "\n",
    "3. Two convolutional layers (after concatenation) per upsampling level.\n",
    "\n",
    "2. LeakyReLU activation, no batch normalization.\n",
    "        \n",
    "3. Downsampling through Maxpooling.\n",
    "\n",
    "4. Upsampling through transpose convolutional layers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnet = models.unet_plus_2d((64, 64, 3), [64, 128, 256, 512], n_labels=3,\n",
    "                           stack_num_down=2, stack_num_up=2,\n",
    "                           activation='LeakyReLU', output_activation='Softmax', \n",
    "                           batch_norm=False, pool=True, unpool=False, name='xnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4**: a R2U-net for binary classification with:\n",
    "\n",
    "1. three down- and upsampling levels.\n",
    "\n",
    "2. Two recurrent convolutional layers with two iterations per down- and upsampling level.\n",
    "\n",
    "2. ReLU activation, no batch normalization.\n",
    "        \n",
    "3. Downsampling through Maxpooling.\n",
    "\n",
    "4. Upsampling through reflective padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_unet = models.r2_unet_2d((64, 64, 3), [64, 128, 256, 512], n_labels=2,\n",
    "                            stack_num_down=2, stack_num_up=1, recur_num=2,\n",
    "                            activation='ReLU', output_activation='Softmax', \n",
    "                            batch_norm=True, pool=True, unpool=True, name='r2-unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5**: a ResUnet-a for 16-label classification with:\n",
    "\n",
    "1. six down- and upsampling levels.\n",
    "\n",
    "2. dilation rates of {1, 3, 15, 31} for shallow layers, {1,3,15} for intermediate layers, and {1,} for deep layers.\n",
    "\n",
    "3. ReLU activation, batch normalization.\n",
    "\n",
    "4. Upsampling through reflective padding.\n",
    "\n",
    "* (Downsampling is fixed to strided convolutional layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received dilation rates: [1, 3, 15, 31]\n",
      "Expanding dilation rates:\n",
      "\tdepth-0, dilation_rate = [1, 3, 15, 31]\n",
      "\tdepth-1, dilation_rate = [1, 3, 15, 31]\n",
      "\tdepth-2, dilation_rate = [1, 3, 15]\n",
      "\tdepth-3, dilation_rate = [1, 3, 15]\n",
      "\tdepth-4, dilation_rate = [1]\n",
      "\tdepth-5, dilation_rate = [1]\n"
     ]
    }
   ],
   "source": [
    "resunet_a = models.resunet_a_2d((128, 128, 3), [32, 64, 128, 256, 512, 1024], \n",
    "                                dilation_num=[1, 3, 15, 31], \n",
    "                                n_labels=16, activation='ReLU', output_activation='Softmax', \n",
    "                                batch_norm=True, unpool=True, name='resunet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equivalently, delation rates can be specified per down- uplampling level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resunet_a = models.resunet_a_2d((128, 128, 3), [32, 64, 128, 256, 512, 1024], \n",
    "                                dilation_num=[[1, 3, 15, 31], [1, 3, 15, 31], [1, 3, 15], [1, 3, 15], [1,], [1,],],\n",
    "                                n_labels=16, activation='ReLU', output_activation='Softmax', \n",
    "                                batch_norm=True, unpool=True, name='resunet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
